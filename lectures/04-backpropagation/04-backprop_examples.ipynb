{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND gate\n",
    "X = np.array([\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "\n",
    "y_flat = np.array([0, 0, 0, 1], dtype=np.int8)\n",
    "# y_flat = np.array([0, 1, 1, 1], dtype=np.int8)\n",
    "y = y_flat[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting stuff\n",
    "def plot_inputs(X, y):\n",
    "    y_flat = y.flatten()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.scatter(X[y_flat == 0,1],X[y_flat == 0,2],color=\"blue\", marker=\"o\", label=\"Output: 0\")\n",
    "    ax.scatter(X[y_flat == 1,1],X[y_flat == 1,2],color=\"red\", marker=\"x\", label=\"Output: 1\")\n",
    "    ax.set_xlabel(\"$x_1$\")\n",
    "    ax.set_ylabel(\"$x_2$\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    return fig, ax\n",
    "\n",
    "def plot_decision(ax, w, colour=[0, 0, 0, 0.2], label=None):\n",
    "    # We get a 1 if w0 + w1x1 + w2x2 >= 0, and a 0 otherwise.\n",
    "    # solving for x2, we get x2 >= -(w0 + w1x1) / w2\n",
    "    if abs(w[2]) > 0:\n",
    "        slope = -w[1] / w[2]\n",
    "        intercept = -w[0] / w[2]\n",
    "        decision_x = np.array([-0.1, 1.1])\n",
    "        ax.plot(decision_x, decision_x * slope + intercept, color=colour, label=label)\n",
    "\n",
    "fig, ax = plot_inputs(X, y)\n",
    "leg = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1 # early choice, gives integer weights\n",
    "\n",
    "def step(v):\n",
    "    \"\"\"Heaviside step function\"\"\"\n",
    "    return (v >= 0).astype(int)\n",
    "\n",
    "# Initialize weights to zero\n",
    "w = np.zeros((3, 1))\n",
    "\n",
    "y_hat = X @ w\n",
    "epochs = 0\n",
    "\n",
    "while not all(y == y_hat):\n",
    "    # one instance at a time\n",
    "    plot_decision(ax, w)\n",
    "    print(f\"Epoch {epochs}: w = {w.flatten()}\")\n",
    "    for i in range(4):\n",
    "        x_i_T = X[i:i+1, :] # preserve the singleton dimension\n",
    "        y_hat[i] = step(x_i_T @ w)\n",
    "        if y_hat[i] != y[i]:\n",
    "            w += eta * (y[i] - y_hat[i]) * x_i_T.T\n",
    "    \n",
    "    epochs += 1\n",
    "\n",
    "print(f\"Final w = {w.flatten()}\")\n",
    "\n",
    "plot_decision(ax, w, \"green\", \"Final boundary\")\n",
    "ax.set_aspect(\"auto\")\n",
    "leg.remove()\n",
    "leg = ax.legend()\n",
    "ax.set_title(f\"AND solution converged after {epochs} epochs\")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify XOR solution\n",
    "# X is unchanged from prior inputs\n",
    "y_xor = np.array([0, 1, 1, 0])\n",
    "w_1 = np.array([\n",
    "    [-3/2, -1/2],\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "])\n",
    "\n",
    "# intermediate \"hidden\" space - inputs to the next layer\n",
    "H = step(X @ w_1)\n",
    "# add on the bias term\n",
    "H = np.column_stack((np.ones(4), H))\n",
    "w_2 = np.array([\n",
    "    [-0.5],\n",
    "    [-1],\n",
    "    [1],\n",
    "])\n",
    "\n",
    "fig_h, ax_h = plot_inputs(H, y_xor)\n",
    "plot_decision(ax_h, w_2, label=\"Decision boundary for layer 2\")\n",
    "ax_h.set_aspect(\"auto\")\n",
    "ax_h.set_xlabel(\"$h_1$\")\n",
    "ax_h.set_ylabel(\"$h_2$\")\n",
    "ax_h.legend()\n",
    "\n",
    "print(step(H @ w_2).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy mlp example\n",
    "# forward pass\n",
    "x = np.array([2, 3])\n",
    "y = 1\n",
    "w1 = np.array([[-0.78, 0.13], [0.85, 0.23]])\n",
    "w2 = np.array([1.8, 0.40])\n",
    "\n",
    "iterations = 20\n",
    "eta = 0.01\n",
    "loss = np.zeros(iterations)\n",
    "\n",
    "for i in range(iterations):\n",
    "    # forward pass\n",
    "    y_hat = x @ w1 @ w2\n",
    "    \n",
    "    # update loss to keep track of performance\n",
    "    loss[i] = (y_hat - y)**2\n",
    "\n",
    "    # backpropagate!\n",
    "    w2_partials = (y_hat - y) * (x @ w1)\n",
    "    w1_partials = w2_partials @ x\n",
    "\n",
    "    # take a step in the opposite direction\n",
    "    w1 = w1 - eta * w1_partials\n",
    "    w2 = w2 - eta * w2_partials\n",
    "\n",
    "plt.plot(loss)\n",
    "\n",
    "# check how well we did\n",
    "print(\"Final prediction:\", x @ w1 @ w2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
